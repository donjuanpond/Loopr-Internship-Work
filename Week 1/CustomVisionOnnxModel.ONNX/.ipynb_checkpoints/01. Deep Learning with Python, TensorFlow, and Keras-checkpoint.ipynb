{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a213a2a",
   "metadata": {},
   "source": [
    "# Neural Networks Overview\n",
    "\n",
    "Before we start getting into deep learning, we need to have a balance between treating neural networks like a total black box which we don't understand at all and  understanding every detail of them. Basically, a neural network consists of some sort of input (this might be in the form of $x_1$ $x_2$ $x_3$ or something like that) which the network tries to map to some sort of output. This output might be detecting whether an image is of a dog or of a cat - it would then have two neurons, one for dog and one for cat. A neuron is really just a thing that holds a value between 0 and 1 (the value measures its activation) and is connected to other neurons.\n",
    "\n",
    "Now, our question becomes \"how do we map our input neurons to our output neurons?\" - to do this, we have several hidden layers of neurons we can use (note that a neural network with more than 1 hidden layer can be called a 'deep neural network'). Each of the inputs $x_1$ $x_2$ and $x_3$ gets connected to each of the neurons in the first hidden layer, which then connects to the next layer, so on and so forth to the output neurons. The reason these layers exist are to break down complex things into simpler ones, going all the way down to the input. For example, if you have a network which takes in a grid of pixels as input (each pixel of the input is a neuron with value depending on its grayscale value) and tries to recognize a handwritten digit from it, each layer would group together those individual pixels up layer by layer to be able to tell what digit, from 0 to 9, the input is. In this example, the first hidden layer from the input might group the digit into components such as edges of the number at different areas, the next might group it into shapes such as loops or lines which could make up other digits, and the output would be able to tell which digit it is.\n",
    "\n",
    "Let's zoom in to a specific example where our hope is for one particular neuron in the second layer to detect whether the image has an edge in a specific region of the pixel grid. What parameters should exist here, what dials and knobs should we be able to tweak in order to make the network expressive enough to potentially capture this pattern? What we'll do is assign a weight from our neuron to all the neurons of the first layer (the input neurons, so basically the pixels of input) - these weights are just numbers. Then, what we do is take all the activations from the first layer (all neurons from one layer connect to the next) and compute their weighted sum according to the weights of their connections to our neuron. If we want to detect if there is an edge in a region, we might put positive weights associated with areas where we would expect bright pixels for an edge to be drawn, and negative weights associated with areas where we don't expect pixels - this would help us to generate a numerical representation of whether or not there is an edge there. \n",
    "\n",
    "Since this weighted sum could be any number but we want neuron activations to lie between 0 and 1, we would take our weighted sum and put it through some function that squishes it into this range, be it the sigmoid or ReLU function. However, what if we wnat to make it so that the function isn't active past a weighted sum of 0 like the sigmoid might make it - what if we only want it to be meaningfully active when the weighted sum > 10? We can do this by adding a __bias__ to the weighted sum (in our case negative 10) before it goes into the sigmoid squisher.\n",
    "\n",
    "Machine learning models actually learn through the process of gradient descent and backpropagation, which are explained in detail in [this](https://www.youtube.com/watch?v=IHZwWFHWa-w&list=RDCMUCYO_jab_esuFRV4b17AJtAw&index=2) and [this](https://www.youtube.com/watch?v=Ilg3gGewQ5U&list=RDCMUCYO_jab_esuFRV4b17AJtAw&index=3) video.\n",
    "\n",
    "***\n",
    "\n",
    "Now that we understand the basics of neural networks, we can build one out! We can do this with the tool known as TensorFlow, which we can install with the following code in command prompt:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6dc65b01",
   "metadata": {},
   "source": [
    "pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab0b1d8",
   "metadata": {},
   "source": [
    "Let's start off by importing tensorflow and importing a database which we will build our machine learning model off. This database, known as MNIST, actually stores thousands of 28x28 pixel images of handwritten digits from 0 to 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c76bc4f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec30dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604ab842",
   "metadata": {},
   "source": [
    "Now, our idea is to take these pixel values in our MNIST database and feed them through our neural network, which will then analyze the image and output what digit it thinks the image represenst. Using this MNIST database is kind of a \"hello world\" in machine learning, it's the first thing which everyone learning it does. Now what we want to do is unpack that data into training and testing variables (train-test split):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "898001a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we just use simple tuple unpacking to separate our data out\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a1e71f",
   "metadata": {},
   "source": [
    "Now, to show what that data actually is, we can use matplotlib (specifically the `.imshow()` function) to show our image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4699e16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "#First we see the raw data of what the first piece of x training data is. This is just a multidimentional array, which is\n",
    "#what a tensor is.\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b89837f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Now, let's see how this same data looks as an image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#We have to put in the 'cmap' parameter to tell plt that this is a grayscale image that is not supposed to have any color\n",
    "plt.imshow(x_train[0], cmap = plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567ee90b",
   "metadata": {},
   "source": [
    "Now, we want to normalize (or scale) this data (normalization is just the cleaning and organizing of the data into a standard, or normal, format). We can do this by using the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0896b020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, we are basically using Keras (an interface for tensorflow) in order to normalize data. The axis=1 parameter here\n",
    "#shows that we are doing this with x data which goes along horizontally (that is what axis=1 represents)\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f006921",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = tf.keras.utils.normalize(x_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62c936f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00393124 0.02332955 0.02620568 0.02625207 0.17420356 0.17566281\n",
      "  0.28629534 0.05664824 0.51877786 0.71632322 0.77892406 0.89301644\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.05780486 0.06524513 0.16128198 0.22713296\n",
      "  0.22277047 0.32790981 0.36833534 0.3689874  0.34978968 0.32678448\n",
      "  0.368094   0.3747499  0.79066747 0.67980478 0.61494005 0.45002403\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.12250613 0.45858525 0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.32790981 0.36833534 0.3689874  0.34978968 0.32420121\n",
      "  0.15214552 0.17865984 0.25626376 0.1573102  0.12298801 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.04500225 0.4219755  0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.32790981 0.28826244 0.26543758 0.34149427 0.31128482\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.1541463  0.28272888 0.18358693 0.37314701\n",
      "  0.33153488 0.26569767 0.01601458 0.         0.05945042 0.19891229\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.0253731  0.00171577 0.22713296\n",
      "  0.33153488 0.11664776 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.20500962\n",
      "  0.33153488 0.24625638 0.00291174 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.01622378\n",
      "  0.24897876 0.32790981 0.10191096 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04586451 0.31235677 0.32757096 0.23335172 0.14931733 0.00129164\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.10498298 0.34940902 0.3689874  0.34978968 0.15370495\n",
      "  0.04089933 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06551419 0.27127137 0.34978968 0.32678448\n",
      "  0.245396   0.05882702 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.02333517 0.12857881 0.32549285\n",
      "  0.41390126 0.40743158 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.32161793\n",
      "  0.41390126 0.54251585 0.20001074 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06697006 0.18959827 0.25300993 0.32678448\n",
      "  0.41390126 0.45100715 0.00625034 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05110617 0.19182076 0.33339444 0.3689874  0.34978968 0.32678448\n",
      "  0.40899334 0.39653769 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.04117838 0.16813739\n",
      "  0.28960162 0.32790981 0.36833534 0.3689874  0.34978968 0.25961929\n",
      "  0.12760592 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.04431706 0.11961607 0.36545809 0.37314701\n",
      "  0.33153488 0.32790981 0.36833534 0.28877275 0.111988   0.00258328\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.05298497 0.42752138 0.4219755  0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.25273681 0.11646967 0.01312603 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.37491383 0.56222061\n",
      "  0.66525569 0.63253163 0.48748768 0.45852825 0.43408872 0.359873\n",
      "  0.17428513 0.01425695 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.92705966 0.82698729\n",
      "  0.74473314 0.63253163 0.4084877  0.24466922 0.22648107 0.02359823\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#When we run this again with the normalized data, we can see that all values have been squished to between 0 and 1 as to \n",
    "#normalize the data and make it readable for our neural network. Normalization takes all the data, subtracts it by the mean,\n",
    "#then divides by either the range or the standard deviation.\n",
    "plt.imshow(x_train[0], cmap = plt.cm.binary)\n",
    "plt.show()\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8e6146",
   "metadata": {},
   "source": [
    "Now, let's build a model for our neural network. We use `.Sequential()` because we are making a sequential model - these are appropriate when you have a single input tensor and a single output tensor (which we have here):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19906200",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e94a6ff",
   "metadata": {},
   "source": [
    "From here, we can build on our model by using the `.add()` function. Our first layer is going to be the input layer - however, our images are 28x28 right now, we want them to be completely flat instead. To do this, we could use NumPy and reshape, but we could also use a funtion build into keras known as `.layers.Flatten()` - one of the reasons we want this to be a `layers` type is because, when you have a convolutional neural network, at the end there will often be a densely connected layer, so you need to flatten it before that layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a702e838",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b55762",
   "metadata": {},
   "source": [
    "Now, we want to add two hidden layers. To do this, we can run our model.add() function but for dense layers instead of flattened ones. The first parameter we pass in here is \"how many neurons in the layer\" - we are going to put in 128. After this, the `activation` parameter tells what activation function we wish to use (this would be our squishification function mentioned above) - we pass in `activation=tf.nn.relu` to signify that we are using a ReLU function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dcc804ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e708c3",
   "metadata": {},
   "source": [
    "Now, we need to add our final output layer. We do this by adding another dense layer, but instead of 128 output neurons, we want only 10 - this is because we have 10 classifications, one for each digit. Here, we don't want to use ReLU as the activation function as this is a probability distribution (each of the output neurons's values represent the probability for each classification, at least according to the neural network). We will instead use softmax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "215d67a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bb8114",
   "metadata": {},
   "source": [
    "That is our entire model! We are now done with defining the architecture of our model; now what we need to do is define some parameters for the training of this model. We can do this by using the `.compile()` method, which takes the following parameters:\n",
    "\n",
    "* `optimizer`: Here, we pass in the optimizer that we want to use. This is the most complex part of the neural network which basically defines how the network learns. Examples include stochastic gradient descent - we will use \"adam\", which is a form of gradient descent.\n",
    "* `loss`: Here, we input the function for loss (the cost function) which we want our network to minimize\n",
    "* `metrics`: Here, we define the metrics which we want to track (inputted as a list)\n",
    "\n",
    "Here are our inputs for these parameters:\n",
    "\n",
    "* `optimizer`: We use the adam optimizer here, as it is basically the default optimizer used by beginners (similar to ReLU).\n",
    "* `loss`: We will use sparse categorical crossentropy here (in the case of separating into binary classifications such as cats vs dogs, we would use binary instead)\n",
    "* `metrics`: We will just be using accuracy as a metric here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "21b49310",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d47254",
   "metadata": {},
   "source": [
    "Now, we are ready to train our model. To do this, all we need to do is use the following function, inputting our training data and a parameter called `epochs` - an epoch is just a full pass through your entire training dataset, so if we input `epochs = 1`, our neural network will see each unique training example once. We will be inputting `epochs = 3`, meaning that our data set will be passed over 3 times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ebcc8fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2583 - accuracy: 0.9245\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1052 - accuracy: 0.9676\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0719 - accuracy: 0.9774TA: 1s - - ETA: 0s - loss: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x159d15a9070>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca70d93e",
   "metadata": {},
   "source": [
    "Now, this is looking promising! We are seeing 97.74% accuracy with our method, but the question now becomes, \"is it actually good or did it just overfit?\" The hope is that our neural network learned atual attributes and patterns to determine what defines a digit, but our fear is that it just memorized every single sample we passed through - this is known as overfitting, and happens very commonly. To evaluate our model, we can use tuple unpacking for loss and accuracy on the function `.evaluate()`, which takes in x-test data and y-test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "18ab2ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0940 - accuracy: 0.9719\n",
      "\n",
      "Accuracy: 0.9718999862670898\n",
      "Loss: 0.09395774453878403\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"\\nAccuracy: {val_acc}\\nLoss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5488e2bb",
   "metadata": {},
   "source": [
    "We see that our accuracy stat is slightly lower than in the learning and our loss is slightly higher, but this is to be expected. However, our accuracy is still very good, at 97.2%! What we don't want to see is accuracy values that are too close between the training and test (this is a sign of underfitting) or accuracy values that are too far apart, meaning there is a large Delta (this is a sign of overfitting). \n",
    "\n",
    "Now, if we want to save a model, we can simply use the `.save()` method, which takes in our model name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1f5ae324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: first_ml_model.model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('first_ml_model.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecdcf2b",
   "metadata": {},
   "source": [
    "As we can see, it has been written to the assets folder of tensorflow. We can then load this model by using the `.load_model()` method, which takes in the exact name of the model we want to load in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b0145f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('first_ml_model.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67beea05",
   "metadata": {},
   "source": [
    "Finally, if we want to make a prediction, we can use the `.predict()` method, which always takes in a list of test x values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5a5d0011",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = loaded_model.predict([x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2eecf55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.80268223e-09 1.04421485e-08 1.03350226e-06 ... 9.99802768e-01\n",
      "  4.31082405e-08 6.17857040e-06]\n",
      " [5.85763571e-09 2.53258240e-05 9.99972224e-01 ... 2.23710366e-08\n",
      "  1.19533370e-08 1.88827274e-12]\n",
      " [2.52795864e-08 9.99830604e-01 7.77584573e-05 ... 3.53897303e-05\n",
      "  4.08875712e-05 1.19543301e-07]\n",
      " ...\n",
      " [1.39937114e-07 2.87234741e-07 6.30732472e-07 ... 1.34677190e-04\n",
      "  5.29060071e-06 4.97189956e-03]\n",
      " [1.75199574e-07 3.99158893e-07 2.73951066e-08 ... 3.03681311e-08\n",
      "  1.24094313e-05 2.20419460e-09]\n",
      " [1.70837936e-07 1.06234674e-08 4.70553125e-08 ... 1.05700310e-11\n",
      "  3.52905616e-08 2.12970711e-10]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3ff717",
   "metadata": {},
   "source": [
    "As we can see here, predictions is actually a bunch of one-hot arrays, and that's it (one-hot arrays are arrays where all values are 0 except for one). These are our probability distributions, showing the probability that the input is a certain digit. If we want to see what the predicted value for each testcase is, we have to take the argmax of each testcase - we can do this with NumPy for the first testcase as is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "12902e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.argmax(predictions[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485e4b41",
   "metadata": {},
   "source": [
    "We see that our neural network is predicting that the first testcase is an image of a 7. Let's see if it really is a 7 by showing it with matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "95206270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[0], cmap = plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293d3985",
   "metadata": {},
   "source": [
    "As we can see, our prediction has worked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b845728",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
