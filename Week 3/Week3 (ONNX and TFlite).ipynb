{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7/2/2022\n",
    "### YoloV5 TFlite model in Android studio\n",
    "* To run it in android studio, we first have to create metadata for the tflite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadia\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.0)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"ObjectDetector\",\n",
      "  \"description\": \"Identify which of a known set of objects might be present and provide information about their positions within the given image or a video stream.\",\n",
      "  \"subgraph_metadata\": [\n",
      "    {\n",
      "      \"input_tensor_metadata\": [\n",
      "        {\n",
      "          \"name\": \"image\",\n",
      "          \"description\": \"Input image to be detected.\",\n",
      "          \"content\": {\n",
      "            \"content_properties_type\": \"ImageProperties\",\n",
      "            \"content_properties\": {\n",
      "              \"color_space\": \"RGB\"\n",
      "            }\n",
      "          },\n",
      "          \"process_units\": [\n",
      "            {\n",
      "              \"options_type\": \"NormalizationOptions\",\n",
      "              \"options\": {\n",
      "                \"mean\": [\n",
      "                  127.5\n",
      "                ],\n",
      "                \"std\": [\n",
      "                  127.5\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          ],\n",
      "          \"stats\": {\n",
      "            \"max\": [\n",
      "              1.0\n",
      "            ],\n",
      "            \"min\": [\n",
      "              -1.0\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      ],\n",
      "      \"output_tensor_metadata\": [\n",
      "        {\n",
      "          \"name\": \"location\",\n",
      "          \"description\": \"The locations of the detected boxes.\",\n",
      "          \"content\": {\n",
      "            \"content_properties_type\": \"BoundingBoxProperties\",\n",
      "            \"content_properties\": {\n",
      "              \"index\": [\n",
      "                1,\n",
      "                0,\n",
      "                3,\n",
      "                2\n",
      "              ],\n",
      "              \"type\": \"BOUNDARIES\"\n",
      "            },\n",
      "            \"range\": {\n",
      "              \"min\": 2,\n",
      "              \"max\": 2\n",
      "            }\n",
      "          },\n",
      "          \"stats\": {\n",
      "          }\n",
      "        }\n",
      "      ],\n",
      "      \"output_tensor_groups\": [\n",
      "        {\n",
      "          \"name\": \"detection_result\",\n",
      "          \"tensor_names\": [\n",
      "            \"location\",\n",
      "            \"category\",\n",
      "            \"score\"\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadia\\anaconda3\\lib\\site-packages\\tensorflow_lite_support\\metadata\\python\\metadata.py:395: UserWarning: File, 'labels.txt', does not exist in the metadata. But packing it to tflite model is still allowed.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tflite_support.metadata_writers import object_detector\n",
    "from tflite_support.metadata_writers import writer_utils\n",
    "from tflite_support import metadata\n",
    "ObjectDetectorWriter = object_detector.MetadataWriter\n",
    "_MODEL_PATH = r\"C:\\Users\\aadia\\Downloads\\yolov5s-fp16.tflite\"\n",
    "# Task Library expects label files that are in the same format as the one below.\n",
    "_LABEL_FILE = \"labels.txt\"\n",
    "_SAVE_TO_PATH = \"yolo_with_metadata.tflite\"\n",
    "# Normalization parameters is required when reprocessing the image. It is\n",
    "# optional if the image pixel values are in range of [0, 255] and the input\n",
    "# tensor is quantized to uint8. See the introduction for normalization and\n",
    "# quantization parameters below for more details.\n",
    "# https://www.tensorflow.org/lite/convert/metadata#normalization_and_quantization_parameters)\n",
    "_INPUT_NORM_MEAN = 127.5\n",
    "_INPUT_NORM_STD = 127.5\n",
    "\n",
    "# Create the metadata writer.\n",
    "writer = ObjectDetectorWriter.create_for_inference(\n",
    "    writer_utils.load_file(_MODEL_PATH), [_INPUT_NORM_MEAN], [_INPUT_NORM_STD],\n",
    "    [_LABEL_FILE])\n",
    "\n",
    "# Verify the metadata generated by metadata writer.\n",
    "print(writer.get_metadata_json())\n",
    "\n",
    "# Populate the metadata into the model.\n",
    "writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When trying to run this model, we get the following error:\n",
    "![image.png](attachment:image.png)\n",
    "* This is because the model only gives one output for some reason and not the 4 outputs which explain the bounding boxes. Therefore, the TFlite model from LOOPR does not work in the app demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7/3/2022\n",
    "#### Resources\n",
    "* https://devblogs.microsoft.com/azure-sdk/ai-on-iot-edge/?adlt=strict&toWww=1&redig=961F027CF546482AB35BF115E035F0BB -guide\n",
    "* https://pypi.org/project/jetson-emulator/ -emulator\n",
    "* https://rawgit.com/dusty-nv/jetson-inference/dev/docs/html/python/jetson.html -emulator documentation\n",
    "\n",
    "Jetson Nano Emulator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detected 3 objects in image\n",
      "\n",
      "class_desc: bottle\n",
      "<jetson.inference.Detection object>\n",
      "   -- ClassID: 45\n",
      "   -- Confidence: 0.592146\n",
      "   -- Left: 1195.0\n",
      "   -- Top: 668.0\n",
      "   -- Right: 2804.0\n",
      "   -- Bottom: 1593.0\n",
      "   -- Width: 1609.0\n",
      "   -- Height: 925.0\n",
      "   -- Area: 1488325.0\n",
      "   -- Center: (1999.5, 1130.5)\n",
      "\n",
      "class_desc: desk\n",
      "<jetson.inference.Detection object>\n",
      "   -- ClassID: 70\n",
      "   -- Confidence: 0.584934\n",
      "   -- Left: 64.0\n",
      "   -- Top: 197.0\n",
      "   -- Right: 3361.0\n",
      "   -- Bottom: 1294.0\n",
      "   -- Width: 3297.0\n",
      "   -- Height: 1097.0\n",
      "   -- Area: 3616809.0\n",
      "   -- Center: (1712.5, 745.5)\n",
      "\n",
      "class_desc: pizza\n",
      "<jetson.inference.Detection object>\n",
      "   -- ClassID: 60\n",
      "   -- Confidence: 0.982439\n",
      "   -- Left: 843.0\n",
      "   -- Top: 296.0\n",
      "   -- Right: 2808.0\n",
      "   -- Bottom: 2160.0\n",
      "   -- Width: 1965.0\n",
      "   -- Height: 1864.0\n",
      "   -- Area: 3662760.0\n",
      "   -- Center: (1825.5, 1228.0)\n",
      "\n",
      "detectNet,random,03,45,1195,2804,668,1593,70,64,3361,197,1294,60,843,2808,296,2160,.jpg\n"
     ]
    }
   ],
   "source": [
    "#Importing libraries\n",
    "import jetson_emulator.inference as inference\n",
    "import jetson_emulator.utils as utils\n",
    "\n",
    "network = \"ssd-mobilenet-v2\"     # Defines the neural network being used for inference\n",
    "\n",
    "\n",
    "net = inference.detectNet(network, threshold=0.5)   # Creates the detectNet object used in inference, taking the network and\n",
    "                                                    # prediction threshold as input\n",
    "    \n",
    "input_URI = \"rtsp://jetson_emulator:554/detectNet/random_cam/4k\" # Defines a string which represents the input resource path.\n",
    "                                                                 # In this case, the resource path is to a real time stream of\n",
    "                                                                 # random images\n",
    "input = utils.videoSource(input_URI, argv=\"\")\n",
    "output = utils.videoOutput(\"display://1\", argv=\"\")\n",
    "img = input.Capture()\n",
    "detections = net.Detect(img, \"box\")\n",
    "output.SetStatus(\"{:s} | Network {:.0f} FPS\".format(network, net.GetNetworkFPS()))\n",
    "output.Render(img)\n",
    "\n",
    "print(\"detected {:d} objects in image\\n\".format(len(detections)) )\n",
    "for detection in detections:\n",
    "    print(\"class_desc:\", net.GetClassDesc(detection.ClassID))  \n",
    "    print(detection)\n",
    "    \n",
    "print(img.cudaMemory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: This entire process is all bogus and random number generation - there isn't any actual image detection going on, all the info is pre-generated with randint. You need an actual Jetson Nano to be able to run the actual inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7/6/2022\n",
    "### Detectron 2 instance segmentation w/ COCO data\n",
    "_https://gilberttanner.com/blog/detectron2-train-a-instance-segmentation-model/_\n",
    "\n",
    "1. First, gather COCO Json image data. Once that is done, simply run a command to register the COCO data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-860696c99bda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregister_coco_instances\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisualizer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVisualizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMetadataCatalog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDatasetCatalog\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\detectron2\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msetup_environment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msetup_environment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\detectron2\\utils\\env.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0m__all__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"seed_all_rng\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.utils.visualizer import ColorMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create one instance of registration for testing and another for training\n",
    "for d in [\"Train\", \"Test\"]:\n",
    "    register_coco_instances(f\"instance_segment_{d}_7-6-22\", {}, f\"COCO Data/{d}_Coco.json\", \"COCO Data/Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualize images and annotations:\n",
    "\n",
    "dataset_dicts = DatasetCatalog.get(\"instance_segment_Train_7-6-22\") # Get a list of dictionaries, each one representing an\n",
    "                                                                    #      annotated image.\n",
    "    \n",
    "for d in random.sample(dataset_dicts, 3):                           # Iterate through a list of three random images.\n",
    "    img = cv2.imread(d[\"file_name\"])                                # Read in the image using the file name provided\n",
    "    visualizer = Visualizer(img[:, :, ::-1], scale=0.5)             # Get a visualizer of the annotations with detectron2\n",
    "    vis = visualizer.draw_dataset_dict(d)                           # Draw annotations from the dictionary\n",
    "    cv2.imshow('image', vis.get_image()[:, :, ::-1])                # Display the annotated immage\n",
    "    cv2.waitKey(0)                                                  # Waits for a key entry to proceed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Now that we've registered the dataset, we can train the model. We get the cfg file and use a prebuilt instance segmentation model from the model zoo as a starting point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-798c65ba6732>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOUTPUT_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mtrainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDefaultTrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresume_or_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\detectron2\\engine\\defaults.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, cfg)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m         \u001b[1;31m# Assume these objects must be constructed in this order.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_optimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m         \u001b[0mdata_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_train_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\detectron2\\engine\\defaults.py\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(cls, cfg)\u001b[0m\n\u001b[0;32m    512\u001b[0m         \u001b[0mOverwrite\u001b[0m \u001b[0mit\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0myou\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0md\u001b[0m \u001b[0mlike\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdifferent\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m         \"\"\"\n\u001b[1;32m--> 514\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m         \u001b[0mlogger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Model:\\n{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\detectron2\\modeling\\meta_arch\\build.py\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(cfg)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mmeta_arch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMETA_ARCHITECTURE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMETA_ARCH_REGISTRY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeta_arch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0m_log_api_usage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"modeling.meta_arch.\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmeta_arch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mto\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    925\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 927\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m     def register_backward_hook(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    600\u001b[0m             \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 602\u001b[1;33m                 \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    603\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    923\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[0;32m    924\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[1;32m--> 925\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    927\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    209\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_getDeviceCount'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m             raise AssertionError(\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"COCO Data/Images\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.MAX_ITER = 1000\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: We are getting a CUDA error because we are using an Intel graphics card - CUDA only works with NVIDIA graphics cards sadly, and Detectron2 only works with CUDA-enabled torch.\n",
    "\n",
    "### Instead, we will do this through a Google CoLab: https://colab.research.google.com/drive/1riH_3PCjPjZniR6eokGE5cXHJ1s6g-tP#scrollTo=UtMZx9KZuMNk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7/8/2022\n",
    "### YOLOv5 tutorial\n",
    "_Following this tutorial: https://www.youtube.com/watch?v=x0ThXHbtqCQ_<br>\n",
    "_Code is running in the following Google CoLab: https://colab.research.google.com/drive/1Tl0Vtp1cvzn77a4v-c6hfzkqfWL9F0RP#scrollTo=ZbUn4_b9GCKO_\n",
    "_Roboflow stuff is at https://app.roboflow.com/micasheets/blister-detection/3_\n",
    "\n",
    "1. First, we clone YOLOv5 using Git, and install dependencies as well as some necessary packages.\n",
    "2. Use app.roboflow.com and use the free community tool convert annotated COCO Json data into the proper format usable by YOLOv5 (https://roboflow.com/convert/coco-json-to-yolov5-pytorch-txt) - note that you have to upload a folder containing 3 subfolders - train, test, and valid. Train must contain all training images and the training COCO Json file, as with test.\n",
    "3. Run some code to get the annotated data into CoLab using OS and Roboflow\n",
    "4. Train the model by running the train.py file, giving inputs such as image size, batch size, epoch number, and starting weights.\n",
    "5. Run inference by running the detect.py file, giving inputs such as threshold, image path, and image size\n",
    "6. Display inference results by entering folder where they are located and displaying them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
